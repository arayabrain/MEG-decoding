# ========model========
image_encoder: vit_clip16
## brain encoder
window:
  start: -0.5 # [s]
  end: 1.0 # [s]
preprocs:
  brain_resample_rate: 120 # 1000 # Hz
  baseline_len_sec: 0
  brain_filter: [0.5, 120] # [2,5] #[1.0, 60] # null is allowed
  last4layers: False       # if True, the brain_encoder's emsize will be 1024, not 512
  # subject_wise: True       # whether to scale each subject's EEG dataset individually (only for Brennan2018)
  clamp: True
  clamp_lim: 20
region:
  - occipital/left
  - occipital/right
  - frontal/left
  - frontal/right
  - temporal/left
  - temporal/right
  - parietal/left
  - parietal/right
  - central/left
  - central/right 

ch_region_path: './data/GOD/ch_region.json'
montage_path: './data/GOD/montage.csv'
# ========prerpocessing========
preprocess: fs120_dura1500_eegnet

# ========dataset========
dataset_name:
    train:
        # drama: sbj_1-session_all #all # all 1_3, 1~3
        # GOD: sbj_1-train-session_1_2_3_4_5_7_8_9_10_11
        things: sbj_1-train-session_all
    val:
        # GOD: sbj_1-train-session_6_12
        things: sbj_1-val-session_all
dataset_yaml:
    drama: drama/drama_config.yaml # region 160 ch
    GOD: GOD/god_config.yaml
    things: things/things_config.yaml
total_limit:
    train:
        # GOD: 6000
        # drama: 12000 # total number of samples across sessions about: 31200
        things: 30000
    val:
        # GOD: 1200 # total number of samples across sessions
        things: 3000

# ========path========
h5_root: ../../../dataset/ssl_dataset/sbj1/regression
image_encoder_path: null # null is allowed
save_root: '/home/yainoue/meg2image/results/20231101_sbj01_eegnetdeep_cv_norm_regression_clip_things2'
wandb_key_path: /home/yainoue/wandb_inoue.txt
# ===== Training settings ====
use_wandb: True
reproducible: true
use_sampler: false
z_scoring: true
rest_duration: 60
num_workers: 8
batch_size: 256 # original: 64, paper: 128
updates: 200
lr: 3e-4
lr_scheduler: none # cosine or multistep or none
lr_multistep_mlstns: [0.4, 0.6, 0.8, 0.9]
lr_step_gamma: 0.5
epochs: 300
reduction: mean

# ==== Architecture ==== #
model: eegnet_deep
k1: 60 # 960
k2: 6 # 96
F1: 32
F2: 96
D: 3
# p0: 10
p1: 2 # 40
p2: 5 # 80
dr1: 0.1
dr2: 0.1
num_channels_per_patch: 16
use_dilaton: true
stride1: 2
stride2: 2
num_conv_time_layers: 5
num_conv_emb_layers: 5
k_div: 2
n_mel: 512
t_mel: 1
num_channels: 271

init_temperature: 5.1
temp_trainable: true
criterion: clip

normalize_image_features: True
normalize_meg : True
memory_efficient: True
channel_size: null # dummy not use